{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fbde2db-3558-4854-9598-f96276597c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "284d406c-8d73-4eaf-b2e7-f4e4b39990fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s: i for i, s in enumerate(chars, 1)}\n",
    "stoi['.'] = 0\n",
    "itos = {i: s for s, i in stoi.items()}\n",
    "\n",
    "vocab_size = len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5074989-42d8-4385-bd8f-4d780e0bda27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182359, 3]) torch.Size([182359])\n",
      "torch.Size([22793, 3]) torch.Size([22793])\n",
      "torch.Size([22994, 3]) torch.Size([22994])\n"
     ]
    }
   ],
   "source": [
    "block_size = 3\n",
    "\n",
    "def build_dataset(words):\n",
    "    block_size = 3\n",
    "    X, Y = [], []\n",
    "\n",
    "    for w in words:\n",
    "\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(4)\n",
    "random.shuffle(words)\n",
    "\n",
    "n1 = int(0.8*len(words)) #80% of words\n",
    "n2 = int(0.9*len(words)) #90% of words\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9677684c-5cd9-4164-aecd-07205342b115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function used to compare manual gradients to PyTorch gradients\n",
    "\n",
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f5d6382-e1db-4692-8209-f8ba27784293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ad49e73-ef81-4fe5-b22b-d80c4a568a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ded1ddb8-e29c-455f-ae26-63bb3ac50099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.498119592666626"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "# BatchNorm layer\n",
    "bnmeani = (1/n)*(hprebn.sum(0, keepdim=True))\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0513274e-32d0-46b9-8adb-145def129d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlogprob        | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = - 1 / n\n",
    "\n",
    "cmp('dlogprob', dlogprobs, logprobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68b81590-4993-4cd3-afe1-551c5752be1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0312)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs.grad[range(n), Yb][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9009a2db-9bb9-4290-a183-b560bdf5b2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dprobs = ( 1.0 / probs) * dlogprobs\n",
    "\n",
    "cmp('probs', dprobs, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73975846-fd36-4106-9639-29ebd9aecd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "# just multiplication derivative, with the propagate of the chain rule\n",
    "# because during the multiplication the result is being summed across 1st dimension\n",
    "\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "474302dd-2854-4692-8376-1cb84251c7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(counts * dprobs).sum(1).shape, dcounts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9897a60b-f7ab-44bf-87bb-fbbed30c1901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts          | exact: False | approximate: False | maxdiff: 0.0040018633008003235\n"
     ]
    }
   ],
   "source": [
    "dcounts = counts_sum_inv * dprobs # counts is used twice i.e in counts_sum_inv and count_sum\n",
    "# `counts * counts_sum_inv` considering this\n",
    "cmp('counts', dcounts, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f8a33dc-810a-4537-adcd-110b54b3b9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dcounts_sum = (- counts_sum ** -2) * dcounts_sum_inv\n",
    "\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ce6a6ad-1cb1-4bd9-8cb0-a68cb31dfe8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dcounts +=torch.ones_like(counts) * dcounts_sum\n",
    "# `counts.sum(1, keepdims=True)` considering this\n",
    "cmp('counts', dcounts, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f9a5032-2802-474d-9683-ad53fe6c556b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norms_logits    | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dnorms_logits = counts * dcounts\n",
    "# norm_logits.exp()\n",
    "cmp('norms_logits', dnorms_logits, norm_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f374be9-66e9-4ba7-92a8-b1a6f6d15846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_logits.shape, logits.shape, logit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25304f6c-b269-4e91-ab2a-56486481a6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dlogits = dnorms_logits.clone()\n",
    "# `logits - logit_maxes` considering this\n",
    "dlogit_maxes = (-dnorms_logits).sum(1, keepdim=True)\n",
    "\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd1df362-735f-4634-a835-7310a9d59cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x119543070>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc36647b-0b57-46f1-821a-18a3a125d81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# considering `logits.max(1, keepdim=True).values`\n",
    "\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "\n",
    "cmp('logits', dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82973d99-bb94-4140-b484-0d22f41e998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh =  dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68a12944-0ad2-40e7-b6e8-1a3f78a8e6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dhpreact = (1.0 - h**2) * dh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd7b2bd-0f9b-4e19-806c-18f1b2f0f4d7",
   "metadata": {},
   "source": [
    "[Resume Here](https://youtu.be/q8SA3rM6ckI?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&t=3523)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "485df3a9-7d08-45b8-b9b7-e8aac7a625a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norms_logits    | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('logprob', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norms_logits', dnorms_logits, norm_logits)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
